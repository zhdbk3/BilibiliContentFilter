# 哔哩哔哩内容过滤器

## 背景

现在 B 站的审核机制莫名其妙，各种匪夷所思的东西都能过审。再加上推荐算法简直就是一坨，什么垃圾视频和引战视频都能往首页上放，严重影响了用户的日常使用体验。

甚至，“不感兴趣”按钮只是个前端的摆设，根本不会往服务器发送任何数据包。

## 功能

设置指定的规则，利用 AI 审核屏蔽掉你不想看的视频！

当前可以屏蔽：

- 首页
- 已打开视频旁边的推荐
- 搜索页面

## 许可证

Hippocratic License 3.0 + Copyleft module

## 安装

### 前端

1. 安装脚本猫 (ScriptCat) 浏览器插件
2. 进入脚本猫主页 > 已安装脚本 > 新建脚本 > 本地导入 > 选择 `bilibiliContentFilter.user.js`

   或者也可以直接在 https://scriptcat.org/zh-CN/script-show-page/3978 安装
3. 点击该脚本的设置（小齿轮⚙图标），设置屏蔽规则，格式这样写：
   ```markdown
   - 规则 1
   - 规则 2
   - ...
   ```

### 后端

你需要一个小或大语言模型来进行判断，你可以选择[本地部署](#本地部署以-ollama-为例)或[远程调用](#远程调用)。

#### 本地部署（以 Ollama 为例）

> [!NOTE]
> 在开始之前，请先看一下你的电脑配置是否能带动至少 4B 的小模型（约需要空闲的 3.3 GB 显存，1.0 GB 内存），建议模型参数量至少 8B（约 5.5 GB 显存，1.0 GB 内存）。
>
> 如果不能，建议[远程调用](#远程调用)，否则模型太小的话效果会非常差。

1. 配置环境变量 `OLLAMA_ORIGINS` 为 `*`（搜索环境变量 > 编辑系统环境变量 > 环境变量(N)... > （用户或系统均可）新建(N)...）
2. 前往 [Ollama 官网](https://ollama.com/download)下载 Ollama 安装包
3. 通过命令行安装 Ollama：
   ```shell
   OllamaSetup.exe /DIR=安装路径
   ```
   然后还是会打开图形化界面，跟随指引安装即可

   ~~（你嫌 C 盘空间多得用不完的话也可以直接双击打开）~~
4. 打开 Ollama（桌面上没有快捷方式的话就打开开始菜单，把 Ollama 这只可爱的小羊驼拖到桌面上），左上角展开菜单 > Settings > Model location 设置你的模型存储位置

   ~~（你嫌 C 盘空间多得用不完的话也可以保持默认）~~
5. 选择一个模型（可在 Ollama 官网上方 Search models），推荐 qwen3:8b 或更大，小一点的 qwen3:4b-instruct 也可以（详见[各模型表现评测 > 本地部署](#本地部署)），在命令行里执行：
   ```shell
   ollama pull 模型名（如 qwen3:8b）
   ```
6. 填写脚本设置：
    - 模型：你的模型名，如 qwen3:8b
    - API 端点 URL：http://127.0.0.1:11434/api/generate
    - API 密钥：留空
    - API 格式：Ollama

> [!NOTE]
> 使用该脚本时，Ollama 必须是开启状态。
>
> Ollama 会开机自启，如果你不想要的话可以用杀毒软件禁了，不过也可以留着防止刷 B 站的时候忘了开。

#### 远程调用

1. 前往一个模型平台（如 OpenRouter 或硅基流动）注册账号，拿到你的 API 密钥
2. 查阅该平台的 API 文档，获取 OpenAI 兼容的 API 端点 URL（一般格式为 https://api.xxx.yyy/v1/chat/completions ）
3. 选择一个模型，推荐 Qwen3 系列的（详见[各模型表现评测 > 远程调用](#远程调用-1)）
4. 填写脚本设置，API 格式选择 OpenAI 兼容

~~使用时，请确保网络连接~~ 不是没网刷什么 B 站啊喂！

## 各模型表现评测

### 本地部署

|        模型         |      表现       |
|:-----------------:|:-------------:|
|  deepseek-r1:8b   | 过于宽松，起不到防御效果  |
|    llama3.1:8b    |  大量误杀，影响正常使用  |
|   **qwen3:8b**    |   **⭐效果较好**   |
| qwen3:4b-instruct | 防御效果较好，但有少量误杀 |
|    qwen3:1.7b     |  大量误杀，影响正常使用  |

### 远程调用

声明：下表所提到的“延迟巨高”，无法确定是模型本身问题还是其他原因导致，仅供参考。

|              模型              |       表现       |
|:----------------------------:|:--------------:|
|         DeepSeek-R1          |  稍微有点宽松，延迟巨高   |
|         DeepSeek-V3          |   较宽松，防御效果较差   |
| **Qwen3-235B-A22B-Instruct** |   **⭐效果最好**    |
|  **Qwen3-30B-A3B-Instruct**  |   **⭐效果较好**    |
|           QwQ-32B            |   关不了深度思考（恼）   |
|     **Kimi-K2-Instruct**     |   **⭐效果较好**    |
|            step3             |  稍微有点宽松，延迟巨高   |
|           GLM-4.5            |  稍微有点宽松，延迟巨高   |
|     ERNIE-4.5-300B-A47B      | 效果较好，但部分时候延迟巨高 |

感谢[薛定谔的按钮](https://github.com/DingerBtn)提供的远程 API 帮助。

~~阿里打钱！~~
